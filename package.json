{
  "name": "llm-roleplay-inference-api",
  "version": "1.0.0",
  "type": "module",
  "license": "MIT",
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js"
  },
  "dependencies": {
    "compression": "^1.7.4",
    "dotenv": "^16.4.5",
    "express": "^4.18.2",
    "helmet": "^8.1.0",
    "pino": "^9.7.0",
    "pino-http": "^10.5.0",
    "pino-pretty": "^13.0.0",
    "redis": "^4.7.0",
    "replicate": "^1.0.1"
  },
  "devDependencies": {
    "@types/compression": "^1.7.3",
    "@types/express": "^4.17.21",
    "@types/jsonwebtoken": "^9.0.5",
    "@types/node": "^20.10.0",
    "typescript": "^5.3.2"
  }
}
